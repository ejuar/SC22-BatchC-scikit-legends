{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Are There Associations With University Tuition & Professional Pay on a State-by-State Basis?\n",
    "\n",
    "### Also, How to Conduct Basic Exploratory Data Analysis\n",
    "Feel free to keep this notebook open, download your own dataset, and follow along with what may be applicable to YOU. <br> Keep in mind, you will almost certainly want to find other ways to manipulate your data. <br> Python has a TON of user created documentation on sites like Stack Overflow.<br> I would recommend searching \"[WhatINeedToDoWithMyDataframe], pandas\" on Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Table Of Contents:\n",
    "* [Import Packages and Define Functions](#Import)\n",
    "* [Loading Data](#Load)\n",
    "* [Exploring Data](#Explore)\n",
    "* [Cleaning Data](#Clean)\n",
    "* [Analyzing Data](#Analyze)\n",
    "* [Visualizing Data](#Visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import Packages and Define Functions <a class=\"anchor\" id=\"Import\"></a>\n",
    "##### You should have a section that imports necessary packages and defines any functions at the top of every notebook, anyone know why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<details> If packages are not imported before they are used, you will receive errors. \n",
    "    <br> It is easiest to 'run all' cells which will go from top to bottom when coming back to your notebook after a break. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### This section will start almost empty, you will add to it as you import new packages and define function.\n",
    "- I always recommend starting with 'import pandas as pd' for dataframe management\n",
    "* Here is the pandas docs - https://pandas.pydata.org/docs/reference/index.html#api\n",
    "- Otherwise you can ignore these for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading Data <a class=\"anchor\" id=\"Load\"></a>\n",
    "- It is best practice keeping this section clean so you know every piece of data you are importing\n",
    "- You will run into errors if you try and reference data before you have loaded it\n",
    "- Keeping data in a 'Data' folder is best for organization too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# make sure you have these files\n",
    "salary_potential = pd.read_csv(\"./Data/salary_potential.csv\")\n",
    "tuition = pd.read_csv(\"./Data/tuition_cost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What does the './' ahead of our folder name do?\n",
    "<details> Pathing is more complex than you might think. The program does not know where to look for your file. \n",
    "    <br> Adding ./ tells the program to start looking from the location where this Notebook is located </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exploring Our Data <a class=\"anchor\" id=\"Explore\"></a>\n",
    "- Here is where we want to inform ourselves on the nitty gritty of what information our data actually holds\n",
    "- How much, what type, is there anything missing, what columns do I need & not need, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Using .head() [first 5 rows] and .tail() [last 5 rows] is a great way to get a first look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "salary_potential.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "tuition.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sometimes column names have extra spaces or we can't see all of them at first, lets print them and get the shape of each to see how much data we are dealing with. <br>(#Rows, #Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(salary_potential.columns)\n",
    "print(\"\")\n",
    "print(salary_potential.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(tuition.columns)\n",
    "print(\"\")\n",
    "print(tuition.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We also want information on what data TYPE each of the columns are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
   ],
   "source": [
    "tuition.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We notice that 'state' and 'room_and_board' are missing some data. State_code is not though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "salary_potential.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We notice that 'make_world_better_percent' is missing some data, missing data can mess with functions down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cleaning and Merging Our Data <a class=\"anchor\" id=\"Clean\"></a>\n",
    "- Lets get rid of redundant columns, either replace or drop missing values, and do any other cleaning we might want\n",
    "- Here we will also merge our different data sources into one cohesive one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First up, lets find the entries with no 'state' from tuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "tuition[tuition['state'].isnull()] # null is the value for an empty variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "tuition[tuition['state'].isnull()].state_code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that there are a few state_codes that don't have state names, we can manually add those.\n",
    "<br>We'll make a function for this and add it to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def fill_state(row):\n",
    "    if row['state_code'] == 'AS':\n",
    "        return 'American Samoa'\n",
    "    elif row['state_code'] == 'DC':\n",
    "        return 'District of Columbia'\n",
    "    elif row['state_code'] == 'PR':\n",
    "        return 'Puerto Rico'\n",
    "    elif row['state_code'] == 'GU':\n",
    "        return 'Guam'\n",
    "    elif row['state_code'] == 'VI':\n",
    "        return 'Virgin Islands'\n",
    "    else:\n",
    "        return row['state']\n",
    "\n",
    "# axis = 1 means do it to the columns (0 is the rows)\n",
    "tuition['state'] = tuition.apply(lambda row : fill_state(row), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we check and see there are no more null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "tuition[tuition['state'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We still have a lot of missing data in the column 'room_and_board' and some in the 'make_world_better_place'\n",
    "<br><br>\n",
    "Since we don't care too much about room_and_board, we'll just drop that column as a whole, but for the other, we will just drop the rows that are missing that data since it is only ~3% of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# drop room and board (axis = 1 --> column)\n",
    "tuition = tuition.drop('room_and_board', axis=1)\n",
    "# drop rows with empty make world better place (axis = 0 --> row)\n",
    "salary_potential = salary_potential.dropna(subset=['make_world_better_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# confirm there are no null values in either dataframe, rows or columns (.sum().sum() condences it into 1 value)\n",
    "print(tuition.isnull().sum().sum(), salary_potential.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Merging our Dataframe\n",
    "To merge our dataframes we need to identify which columns we want to merge on. There's many ways to combine data, you can dive deeper here: <br>https://realpython.com/pandas-merge-join-and-concat/<br> We will be focusing on a simple merge. <br><br> For a simple merge, we want to have two dataframes that have a column by the same name we want to merge on. <br>In our case we want to merge using the 'name' column. We will only have the data of schools that appear identically in both dataframes.<br> One thing to keep in mind, you must merge on a column with the same name so often will need to rename a column from one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# check here to find how to rename - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html\n",
    "# we create a new dataframe called merged_df that is the combined one\n",
    "merged_df = pd.merge(tuition, salary_potential, on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we have a 'state' and 'state_name' column that look duplicative, lets check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "merged_df['state'].equals(merged_df['state_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lets look at the differences, get all the unique 'state' and 'state_names' from all rows where they are not identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "merged_df.loc[~(merged_df['state'] == merged_df['state_name'])]['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "merged_df.loc[~(merged_df['state'] == merged_df['state_name'])]['state_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Many are issues with hyphens, some are not, let's fix the hyphen problem and look at the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "to_replace = ['New-York', 'North-Carolina', 'South-Dakota', 'South-Carolina',\n",
    "       'New-Jersey', 'West-Virginia', 'Rhode-Island', 'New-Hampshire',\n",
    "       'North-Dakota', 'New-Mexico']\n",
    "replace_with = ['New York', 'North Carolina', 'South Dakota', 'South Carolina',\n",
    "       'New Jersey', 'West Virginia', 'Rhode Island', 'New Hampshire',\n",
    "       'North Dakota', 'New Mexico']\n",
    "for i in range(len(to_replace)):\n",
    "    merged_df[\"state_name\"].replace({to_replace[i]: replace_with[i]}, inplace=True)\n",
    "merged_df.loc[~(merged_df['state'] == merged_df['state_name'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After searching Manually, Northwestern College is in Iowa & Sterling College is in Kansas. <br> This shows the importance of double checking your data. <br> I will drop the 'state column' as the 'state_name' column is the accurate one and state_code is unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# inplace = True means that we want the rename to occur in existing dataframe, not return a new one\n",
    "merged_df.drop(['state','state_code'], axis=1, inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we're done cleaning and merging our data, let's turn that into a function, and add it to the top as well to keep our notebook organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# this function cleans and merges our two dataframes, returns one merged_df\n",
    "def clean_and_merge_dfs(tuition, salary_potential):\n",
    "    # drop room and board (axis = 1 --> column)\n",
    "    tuition = tuition.drop('room_and_board', axis=1)\n",
    "    # drop rows with empty make world better place (axis = 0 --> row)\n",
    "    salary_potential = salary_potential.dropna(subset=['make_world_better_percent'])\n",
    "    # we create a new dataframe called merged_df that is the combined one\n",
    "    merged_df = pd.merge(tuition, salary_potential, on='name')\n",
    "    # replace mismatched rows\n",
    "    to_replace = ['New-York', 'North-Carolina', 'South-Dakota', 'South-Carolina',\n",
    "       'New-Jersey', 'West-Virginia', 'Rhode-Island', 'New-Hampshire',\n",
    "       'North-Dakota', 'New-Mexico']\n",
    "    replace_with = ['New York', 'North Carolina', 'South Dakota', 'South Carolina',\n",
    "           'New Jersey', 'West Virginia', 'Rhode Island', 'New Hampshire',\n",
    "           'North Dakota', 'New Mexico']\n",
    "    for i in range(len(to_replace)):\n",
    "        merged_df[\"state_name\"].replace({to_replace[i]: replace_with[i]}, inplace=True)\n",
    "    # drop the duplicative (and slightly incorrect) column 'state'\n",
    "    merged_df.drop(['state','state_code'], axis=1, inplace=True)\n",
    "    # return the merged dataframe\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyzing Our Data <a class=\"anchor\" id=\"Analyze\"></a>\n",
    "Here we want to start looking at our data in the context of our original goal. <br> \"Are There Associations With University Tuition & Professional Pay on a State-by-State Basis?\"<br> To do this I'm going to manually create a dataset, getting first the number of schools in that state, and then the average of statistics I am investigating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def state_stats_df(merged_df):\n",
    "    # get a list of all state_name's\n",
    "    states = merged_df.state_name.unique()\n",
    "\n",
    "    # Create a column in a new dataframe for each stat I want\n",
    "    state_stats = pd.DataFrame(index=states, columns=['number of schools','average early_career_pay',\n",
    "                                                      'average mid_career_pay','average make_world_better_percent',\n",
    "                                                      'average stem_percent','average in_state_tuition','average out_of_state_tuition'])\n",
    "    # Fill in the columns for each state\n",
    "    for state in states:\n",
    "        state_stats.loc[state, 'number of schools'] = len(merged_df[merged_df.state_name == state])\n",
    "        state_stats.loc[state, 'average early_career_pay'] = merged_df[merged_df.state_name == state]['early_career_pay'].mean()\n",
    "        state_stats.loc[state, 'average mid_career_pay'] = merged_df[merged_df.state_name == state]['mid_career_pay'].mean()\n",
    "        state_stats.loc[state, 'average make_world_better_percent'] = merged_df[merged_df.state_name == state]['make_world_better_percent'].mean()\n",
    "        state_stats.loc[state, 'average stem_percent'] = merged_df[merged_df.state_name == state]['stem_percent'].mean()\n",
    "        state_stats.loc[state, 'average in_state_tuition'] = merged_df[merged_df.state_name == state]['in_state_tuition'].mean()\n",
    "        state_stats.loc[state, 'average out_of_state_tuition'] = merged_df[merged_df.state_name == state]['out_of_state_tuition'].mean()\n",
    "    # sort alphabetically by state\n",
    "    state_stats.sort_index(inplace = True)\n",
    "    return state_stats\n",
    "\n",
    "state_stats = state_stats_df(merged_df)\n",
    "state_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We don't need to stay with just the data we have been given, we can combine columns or do additional calculations on them. <br> One example is say we want to get the average 4 year cost of tuition, we can create those columns as well (and a few others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def add_details(state_stats):\n",
    "    # convert all columns to numeric\n",
    "    state_stats = state_stats.apply(pd.to_numeric)\n",
    "    # make columns for four year average out of state and in state total\n",
    "    state_stats['four year average out of state tuition'] = state_stats['average out_of_state_tuition'] * 4\n",
    "    state_stats['four year average in state tuition'] = state_stats['average in_state_tuition'] * 4\n",
    "    # make column calculating how many years on average to repay four year average in and our of state based on average early career pay in index 0\n",
    "    state_stats['years to repay in state 4 year uni based on early career pay'] =  state_stats['four year average in state tuition'] / state_stats['average early_career_pay']\n",
    "    state_stats['years to repay out of state 4 year uni based on early career pay'] = state_stats['four year average out of state tuition'] / state_stats['average early_career_pay'] \n",
    "    # make column calculating how many years on average to repay four year average in and our of state based on average mid career pay in index 0\n",
    "    state_stats['years to repay in state 4 year uni based on mid career pay'] =  state_stats['four year average in state tuition'] / state_stats['average mid_career_pay']\n",
    "    state_stats['years to repay out of state 4 year uni based on mid career pay'] = state_stats['four year average out of state tuition'] / state_stats['average mid_career_pay'] \n",
    "    # move 'years to repay out of state 4 year uni based on early career pay' to the front of the dataframe\n",
    "    state_stats = state_stats.reindex(columns=['four year average in state tuition', 'four year average out of state tuition', 'years to repay in state 4 year uni based on early career pay', 'years to repay out of state 4 year uni based on early career pay',\n",
    "    'years to repay in state 4 year uni based on mid career pay', 'years to repay out of state 4 year uni based on mid career pay',\n",
    "    'number of schools', 'average early_career_pay', 'average mid_career_pay', 'average make_world_better_percent', 'average stem_percent',\n",
    "    'average in_state_tuition','average out_of_state_tuition'])\n",
    "    return state_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "state_stats = add_details(state_stats)\n",
    "state_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notice: This assumes you divert your entire paycheck to student loans and there is no interest. While this gives a guidline, that does hurt the usefullness, as different areas may allow to divert different amounts. Look out for this type of error in your own work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "One of my favorite ways to investigate a dataframe is by using highlighting. <br> Here is a quick example of how to highlight based on how the value compares to the average. <br>\n",
    "These functions are a bit confusing because they are meant to be used by the pandas Apply function. <br> Read more here: https://www.datacamp.com/community/tutorials/pandas-apply <br> It is a way to check each row and do 'something' based on some values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This uses python's \"list comprehension\", which you can find more on here - https://www.w3schools.com/python/python_lists_comprehension.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Highlighting functions for our dataframe\n",
    "def highlight_above_avg(state):\n",
    "    # state_TF will check every row (state) and give a True/False value depending on the condition asked\n",
    "    # e.g. if the value is >.50 quantile (average value) for the column\n",
    "    state_TF = state >= state.quantile(.50)\n",
    "    return ['background: lightgreen' if state else '' for state in state_TF]\n",
    "def highlight_top(s):   \n",
    "    state_TF = s > s.quantile(0.90)\n",
    "    return ['color: blue' if state else '' for state in state_TF]\n",
    "\n",
    "def return_highlighted_df(state_stats):\n",
    "    return state_stats.style.apply(highlight_above_avg).apply(highlight_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add any other filters you can think of to the filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Something to note aboout the below table, some green / blue values could be 'good' while others could be 'bad'. <br>\n",
    "E.g. Having a top 10% in 'average_early_career_pay' could be good, but having a top 10% 'years to repay out of state 4 year uni based on early career pay' would be less awesome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "return_highlighted_df(state_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualizing Our Data <a class=\"anchor\" id=\"Visual\"></a>\n",
    "Last but not least we want to visualize our data, you can see different Python visualization libraries compared here:https://towardsdatascience.com/top-6-python-libraries-for-visualization-which-one-to-use-fe43381cd658 <br> We are using Plotly, as it is the most powerful and simple out of the box. <br> You can see some of the capabilities of Plotly in their documentation here: https://plotly.com/python/ <br> Note: if while running this you get an error 'PX IS NOT DEFINED' you did not import plotly.express (replace plotly with plotly.express in the import)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First things first, now that we have completed our calculations we will turn the index into a named column for ease of graphing and we need to include state code if we want to graph on a map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# turn the index into a column\n",
    "state_stats_extras = state_stats.reset_index(level=0)\n",
    "# rename index to state\n",
    "state_stats_extras.rename({'index': 'state'}, axis=1, inplace=True)\n",
    "# finds each state and adds the code\n",
    "state_stats_extras = state_stats_extras.merge(tuition[['state','state_code']], on='state').drop_duplicates().reset_index(drop=True)\n",
    "state_stats_extras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Define a function to add these last extras that need to be applied after our numerical calculations (highlighting for example)\n",
    "# Don't forget to pass in tuition as a parameter because you merge with it\n",
    "def add_extras(state_stats,tuition):\n",
    "    # turn the index into a column\n",
    "    state_stats_extras = state_stats.reset_index(level=0)\n",
    "    # rename index to state\n",
    "    state_stats_extras.rename({'index': 'state'}, axis=1, inplace=True)\n",
    "    # add the state_code column\n",
    "    state_stats_extras = state_stats_extras.merge(tuition[['state','state_code']], on='state').drop_duplicates().reset_index(drop=True)\n",
    "    return state_stats_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = px.scatter(state_stats_extras, x='four year average in state tuition', y='average mid_career_pay',\n",
    "                 color='state',size='average make_world_better_percent',\n",
    "                 trendline=\"ols\", trendline_scope = 'overall',\n",
    "                 title= 'Average In State Tuition vs Average % of Students Graduating with STEM Degrees')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = px.scatter(state_stats_extras, x='average stem_percent', y='average early_career_pay',color='state',\n",
    "                 trendline=\"ols\", trendline_scope = 'overall',\n",
    "                 title= 'Average In State Tuition vs Average % of Students Graduating with STEM Degrees')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = px.choropleth(state_stats_extras, locations='state_code', locationmode=\"USA-states\", color=\"four year average in state tuition\", scope=\"usa\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = px.choropleth(state_stats_extras, locations='state_code', locationmode=\"USA-states\", color=\"average early_career_pay\", scope=\"usa\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add any more ideas you have here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "ds_env",
   "resource_dir": "/projects/66ddc8e4-4410-423b-929c-a2b80762c7ad/.local/share/jupyter/kernels/ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}